# -*- coding: utf-8 -*-
"""Colab _LAB03.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1C5uIfJz6s7vmzQtcZFQ3fOEv18r27IuA
"""

import pandas as pd
import numpy as np
import statsmodels.api as sm
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import LabelEncoder
print('Import libraries successfully')

"""# Đọc dữ liệu và quan sát nhanh dữ liệu California Housing Prices đã được chia thành 3 tập Train, Dev, và Test
* Lệnh ``pd.read_csv()`` tham khảo tại trang 47 trong sách Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow
* Lệnh ``df.head()`` tham khảo tại trang 47 trong sách Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow
* Lệnh ``df.info()`` tham khảo tại trang 47 trong sách Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow
"""

df_train = pd.read_csv('housing_train.csv') # Đọc dữ liệu tập Train (Tập dữ liệu việc huấn luyện mô hình)
df_dev = pd.read_csv('housing_dev.csv')     # Đọc dữ liệu tập Dev   (Tập dữ liệu dành cho việc phát triển/tinh chỉnh mô hình)
df_test = pd.read_csv('housing_test.csv')   # Đọc dữ liệu tập Test  (Tập dữ liệu dành cho việc kiểm tra mô hình)

df_train.info() # Kiểm tra thông tin ban đầu dữ liệu (số dòng, số cột, kiểu dữ liệu của các cột)

df_train.head() # Quan sát nhanh 5 dòng dữ liệu đầu tiên

df_dev.info() # Kiểm tra thông tin ban đầu dữ liệu (số dòng, số cột, kiểu dữ liệu của các cột)

df_dev.head() # Quan sát nhanh 5 dòng dữ liệu đầu tiên

df_test.info() # Kiểm tra thông tin ban đầu dữ liệu (số dòng, số cột, kiểu dữ liệu của các cột)

df_test.head() # Quan sát nhanh 5 dòng dữ liệu đầu tiên

"""# Tách thuộc tính "median_house_value" để làm thuộc tính cần dự đoán  cho bài toán hồi quy tuyến tính (Y), các thuộc tính còn lại là dữ kiện (X).
* Lệnh ``df.drop()`` tham khảo tại trang sách số 63 sách tham khảo Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow
"""

train_X = df_train.drop("median_house_value", axis=1)
train_Y = df_train["median_house_value"].copy()
# del df_train

dev_X = df_dev.drop("median_house_value", axis=1)
dev_Y = df_dev["median_house_value"].copy()
# del df_dev

test_X = df_test.drop("median_house_value", axis=1)
test_Y = df_test["median_house_value"].copy()
# del df_test

"""# Kiểm tra các thuộc tính bị khuyết giá trị trong tập Train
* Chúng ta có thể cả các lệnh ``df.isnull()`` hoặc ``df.isna()`` để chỉ giá trị bị khuyết (``True``) / không bị khuyết (``False``)
* Chúng ta dùng tiếp lệnh ``arr.any(axis=1)`` để trả về các dòng chỉ chứa một cột có giá trị ``True``/``False`` nếu các cột chỉ cần tồn tại một thuộc tính ``True``
* Chúng ta tính tổng các dòng kết quả trên bằng lệnh ``arr.sum(axis=0)`` sẽ biết được số trường hợp bị khuyết của mỗi thuộc tính
"""

train_X.isnull()

train_X.isnull().any(axis=1)
# train_X.isna().any(axis=1)

train_X[train_X.isnull().any(axis=1)]
# train_X[train_X.isna().any(axis=1)]

train_X.isnull().sum(axis = 0)
# train_X.isna().sum(axis = 0)

"""# Xử lý các cột bị khuyết dữ liệu trên tập Train
1. Phương án 1: Xóa toàn bộ một dòng có cột dữ liệu bị khuyết
2. Phương án 2: Thay thế giá trị số bằng cách dùng trung bình cộng (``mean``) của toàn cột dữ liệu đó
    * Cách xử lý 1: Dùng lớp ``SimpleImputer`` từ thư viện ``sklearn.impute``
    * Cách xử lý 2: Cách hai thực hiện một số thao tác trên cột

Các bạn có thể tham khảo tại trang số 63 sách Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow
"""

# Cách 1:
imputer_mean = SimpleImputer(missing_values=np.nan, strategy='mean')
imputer_mean.fit(train_X["total_bedrooms"].values.reshape(-1, 1))
tmp_total_bedrooms = imputer_mean.transform(train_X['total_bedrooms'].values.reshape(-1, 1))

# Cách 2:
idx_null = train_X["total_bedrooms"].isnull() # kiểm tra giá trị khuyết
mean_total_bedrooms = train_X["total_bedrooms"][train_X["total_bedrooms"].isna() == False].mean() # tính trung bình cộng các giá trị không bị khuyết
train_X["total_bedrooms"].fillna(mean_total_bedrooms, inplace=True) # thay thế các dòng không bị khuyết bởi giá trị trung bình
print(train_X["total_bedrooms"][idx_null == True]) # in ra màn hình giá trị các dòng bị khuyết ban đầu để kiểm tra

print((train_X["total_bedrooms"] == tmp_total_bedrooms.squeeze()).all()) # Kiểm tra kết quả Cách 1 và Cách 2 có giống nhau hay không?

print((train_X["total_bedrooms"].isna() == False).all()) # Kiểm tra kết quả sau khi áp dụng Cách 2 còn giá trị nào bị khuyết hay không?

"""# Yêu cầu 1: Xử lý các cột bị khuyết dữ liệu trên tập Dev/Test

### Xử lí development set
"""

# Take a look at empty element 
dev_X.isnull()

#Return row-only that has empty element
dev_X.isnull().any(axis = 1)

#Return empty row elements (also their attribute)
dev_X[dev_X.isnull().any(axis = 1)]

#Return attribute with total empty row contains it
dev_X.isnull().sum(axis = 0)

# Method 1: Implement SimpleSimpleImputter class
imputer_mean = SimpleImputer(missing_values=np.nan, strategy='mean')
imputer_mean.fit(dev_X["total_bedrooms"].values.reshape(-1, 1))
tmp_total_bedrooms = imputer_mean.transform(dev_X['total_bedrooms'].values.reshape(-1, 1))

# Method 2: Replace empty element with mean value of their whole attribute in dataset
idx_null = dev_X["total_bedrooms"].isnull() # kiểm tra giá trị khuyết
mean_total_bedrooms = dev_X["total_bedrooms"][dev_X["total_bedrooms"].isna() == False].mean() # tính trung bình cộng các giá trị không bị khuyết
dev_X["total_bedrooms"].fillna(mean_total_bedrooms, inplace=True) # thay thế các dòng không bị khuyết bởi giá trị trung bình
print(dev_X["total_bedrooms"][idx_null == True]) # in ra màn hình giá trị các dòng bị khuyết ban đầu để kiểm tra

#Comparison between 2 methods
print((dev_X["total_bedrooms"] == tmp_total_bedrooms.squeeze()).all()) # Kiểm tra kết quả Cách 1 và Cách 2 có giống nhau hay không?
print((dev_X["total_bedrooms"].isna() == False).all()) # Kiểm tra kết quả sau khi áp dụng Cách 2 còn giá trị nào bị khuyết hay không?

"""### Tương tự đối với test set ta sẽ rút ngắn quá trình làm"""

# Check attributes with empty elements
test_X.isnull().sum(axis = 0)

# Implement SimpleSimpleImputter class
imputer_mean = SimpleImputer(missing_values=np.nan, strategy='mean')
imputer_mean.fit(test_X["total_bedrooms"].values.reshape(-1, 1))
tmp_total_bedrooms = imputer_mean.transform(test_X['total_bedrooms'].values.reshape(-1, 1))

# Replace empty element with mean value of their whole attribute in dataset
idx_null = test_X["total_bedrooms"].isnull() # kiểm tra giá trị khuyết
mean_total_bedrooms = test_X["total_bedrooms"][test_X["total_bedrooms"].isna() == False].mean() # tính trung bình cộng các giá trị không bị khuyết
test_X["total_bedrooms"].fillna(mean_total_bedrooms, inplace=True) # thay thế các dòng không bị khuyết bởi giá trị trung bình
print(test_X["total_bedrooms"][idx_null == True]) # in ra màn hình giá trị các dòng bị khuyết ban đầu để kiểm tra

#Comparison between 2 methods
print((test_X["total_bedrooms"] == tmp_total_bedrooms.squeeze()).all()) # Kiểm tra kết quả Cách 1 và Cách 2 có giống nhau hay không?
print((test_X["total_bedrooms"].isna() == False).all()) # Kiểm tra kết quả sau khi áp dụng Cách 2 còn giá trị nào bị khuyết hay không?

"""### Đã thực hiện kiểm tra đối với train_Y, test_Y, dev_Y và không phát hiện thấy thành phần nào bị rỗng"""

print(dev_Y.isnull().sum(axis = 0),
      train_Y.isnull().sum(axis = 0),
      test_Y.isnull().sum(axis = 0))

"""# Yêu cầu 2: Thực hiện các thí nghiệm với việc thêm các thuộc tính tích lũy dẫn
Chúng ta có danh sách các thuộc tính: ``longitude``, ``latitude``, ``housing_median_age``, ``total_rooms``, ``total_bedrooms``, ``population``, ``households``, ``median_income``, ``ocean_proximity``

1. Thí nghiệm 1: ``longitude``
2. Thí nghiệm 2: ``longitude``, ``latitude``
3. Thí nghiêm 3: ``longitude``, ``latitude``, ``housing_median_age``
4. Thí nghiệm 4: v.v...

Lưu ý: Trong quá trình làm, các bạn sẽ tham khảo cách xử lý thuộc tính ``ocean_proximity`` bằng lớp ``LabelEncoder`` từ thư viện ``sklearn.preprocessing``
"""

#model1
features_list_1 = ["longitude"]
model_1 = sm.OLS(train_Y, train_X[features_list_1]).fit()
rmse_train_1 = mean_squared_error(train_Y, model_1.predict(train_X[features_list_1]), squared=False)
# If True returns MSE value, if False returns RMSE value.
rmse_dev_1 = mean_squared_error(dev_Y, model_1.predict(dev_X[features_list_1]), squared=False)
rmse_test_1 = mean_squared_error(test_Y, model_1.predict(test_X[features_list_1]), squared=False)

#model2
features_list_2 = ["longitude", "latitude"]
model_2 = sm.OLS(train_Y, train_X[features_list_2]).fit()
rmse_train_2 = mean_squared_error(train_Y, model_2.predict(train_X[features_list_2]), squared=False)
rmse_dev_2 = mean_squared_error(dev_Y, model_2.predict(dev_X[features_list_2]), squared=False)
rmse_test_2 = mean_squared_error(test_Y, model_2.predict(test_X[features_list_2]), squared=False)

"""### Trước khi đi sâu vào với việc thêm các thuộc tính tích lũy dần, ta quan sát mối quan hệ giữa các thành phần trong dataset trước tiên để thực hiện thí nghiệm"""

#Create dataframe contains all data (dev,test,train)
df_copy = df_train.copy()
df_copy.head()

#Append df_dev,df_test to get full dataset
df_copy.append(df_dev)
df_copy.append(df_test)
df_copy.head()

corr_matrix = df_copy.corr()
print(corr_matrix['median_house_value'].sort_values(ascending = False))

"""Từ bảng ``corr_matrix`` ta thấy được rằng giá cả nhà ngoài yếu tố vị trí còn có thể phụ thuộc vào: 
*   Mức thu nhập bình quân (``median_income``)
*   Số lượng phòng ngủ (``total_rooms``)
*   Độ tuổi trung bình (``housing_median_age``)

Do chỉ số của các thuộc tính ``population``,``total_bedrooms`` quá thấp nên ta sẽ bỏ qua. Tuy nhiên còn thuộc tính ``ocean_proximity`` ta chưa xem xét đến nên sẽ thực hiện quan ở phần sau.

### Biểu đồ Scatter để mô phỏng điều ta dự đoán và sự tương quan
"""

from pandas.plotting import scatter_matrix
print('Import scatter_matrix successfully')

attributes = ['median_house_value', 'median_income', 'total_rooms', 'housing_median_age']
scatter_matrix(df_copy[attributes],figsize = (10,10))

"""Qua biểu đồ scatter trên ta có thể thấy được rằng một số đặc điểm như sau: 
*   Giá nhà càng cao khi thu nhập trung bình khu vực càng cao
*   Số lượng phòng và giá nhà phụ thuộc vào nhau, từ đây ta có thể tạo ra thêm 1 thuộc tính ``rooms_per_house``
*   Độ tuổi trung bình mua nhà và giá cả nhà dường như không liên quan vì vậy sẽ bỏ qua 

Vậy ta hãy tiến hành thử nghiệm với các thuộc tính ``rooms_per_house``, ``median_income``
"""

# Experiment with room_per_house on full dataset
df_copy['rooms_per_house'] = df_copy['total_rooms']/df_copy['households']
df_copy.head()

#Check correlation matrix again 
corr_matrix = df_copy.corr()
print(corr_matrix['median_house_value'].sort_values(ascending = False))

"""Ta thấy rằng thuộc tính ``bedrooms_per_house`` vừa được tạo ra có mối liên hệ với giá nhà cao hơn so với ``total_rooms`` vì thế ta hãy thử áp dụng để training cho model và rồi thực hiện so sánh giữa 2 ``bedrooms_per_house`` và ``total_rooms``"""

# Add rooms_per_house train,test,dev set
train_X['rooms_per_house'] = train_X['total_rooms']/train_X['households']
dev_X['rooms_per_house'] = dev_X['total_rooms']/dev_X['households']
test_X['rooms_per_house'] = test_X['total_rooms']/test_X['households']

# model 3 room_per_house
# Experiment with feature longtitude, latitude, room_per_house
features_list_3 = ["longitude", "latitude","rooms_per_house"]
model_3 = sm.OLS(train_Y, train_X[features_list_3]).fit()
rmse_train_3 = mean_squared_error(train_Y, model_3.predict(train_X[features_list_3]), squared=False)
rmse_dev_3 = mean_squared_error(dev_Y, model_3.predict(dev_X[features_list_3]), squared=False)
rmse_test_3 = mean_squared_error(test_Y, model_3.predict(test_X[features_list_3]), squared=False)

"""Tiến hành xây dựng model với thuộc tính ``housing_median_age``"""

# model 4 housing_median_age
# Experiment with feature longtitude, latitude, housing_median_age
features_list_4 = ["longitude", "latitude","housing_median_age"]
model_4 = sm.OLS(train_Y, train_X[features_list_4]).fit()
rmse_train_4 = mean_squared_error(train_Y, model_4.predict(train_X[features_list_4]), squared=False)
rmse_dev_4 = mean_squared_error(dev_Y, model_4.predict(dev_X[features_list_4]), squared=False)
rmse_test_4 = mean_squared_error(test_Y, model_4.predict(test_X[features_list_4]), squared=False)

"""Tiến hành xây dựng model với thuộc tính ``median_income``"""

# model 5 median_income
# Experiment with feature longtitude, latitude, median_income
features_list_5 = ["longitude", "latitude","median_income"]
model_5 = sm.OLS(train_Y, train_X[features_list_5]).fit()
rmse_train_5 = mean_squared_error(train_Y, model_5.predict(train_X[features_list_5]), squared=False)
rmse_dev_5 = mean_squared_error(dev_Y, model_5.predict(dev_X[features_list_5]), squared=False)
rmse_test_5 = mean_squared_error(test_Y, model_5.predict(test_X[features_list_5]), squared=False)

"""## Ngoài ra, còn thuộc tính ``ocean_proximity``mà ta chưa xét tới
Ta thường thấy rằng vị trí địa lý ảnh hưởng rất nhiều đến giá cả nhà đất và may mắn thay trong dataset đã phân loại các loại vị trí

Bên dưới là 2 đồ thị biểu thị giá nhà và khu vực được phân loại theo vị trí
"""

df_copy.plot(kind="scatter", x="longitude", y="latitude", alpha=0.4,
            s=df_copy["population"]/100, label="population", figsize=(10,7),
            c="median_house_value", cmap=plt.get_cmap("jet"), colorbar=True,)
plt.legend()

from mlxtend.plotting import category_scatter
print('Import mlxtend.plotting successfully')

category_scatter(x="longitude", y="latitude", label_col = 'ocean_proximity',
                data = df_copy, legend_loc = 'upper left')

# ENCODE LABEL
# Label encode ocean_proximity
le = LabelEncoder()
# training set 
le.fit(train_X['ocean_proximity'])
train_X['ocean_proximity'] = le.transform(train_X['ocean_proximity'])
dict(zip(le.classes_, le.transform(le.classes_)))
# development set
le.fit(dev_X['ocean_proximity'])
dev_X['ocean_proximity'] = le.transform(dev_X['ocean_proximity'])
# test set
le.fit(test_X['ocean_proximity'])
test_X['ocean_proximity'] = le.transform(test_X['ocean_proximity'])

dict(zip(le.classes_, le.transform(le.classes_)))

# model 6 ocean_proximity
features_list_6 = ["longitude", "latitude","ocean_proximity"]
model_6 = sm.OLS(train_Y, train_X[features_list_6]).fit()
rmse_train_6 = mean_squared_error(train_Y, model_6.predict(train_X[features_list_6]), squared=False)
rmse_dev_6 = mean_squared_error(dev_Y, model_6.predict(dev_X[features_list_6]), squared=False)
rmse_test_6 = mean_squared_error(test_Y, model_6.predict(test_X[features_list_6]), squared=False)

# features_list_5 = ["longitude", "latitude","ocean_proximity"]
# model_5 = sm.OLS(train_Y, train_X[features_list_5]).fit()
# rmse_train_5 = mean_squared_error(train_Y, model_5.predict(train_X[features_list_5]), squared=True)
# rmse_dev_5 = mean_squared_error(dev_Y, model_5.predict(dev_X[features_list_5]), squared=True)
# rmse_test_5 = mean_squared_error(test_Y, model_5.predict(test_X[features_list_5]), squared=True)

"""Mô hình với tất cả các thuộc tính kết hợp lại với nhau"""

# model with all atrributes (includes rooms_per_house)
model_all = sm.OLS(train_Y, train_X).fit()
rmse_train_all = mean_squared_error(train_Y, model_all.predict(train_X), squared=False)
rmse_dev_all = mean_squared_error(dev_Y, model_all.predict(dev_X), squared=False)
rmse_test_all = mean_squared_error(test_Y, model_all.predict(test_X), squared=False)

#Delete dataframe after use
del df_train
del df_test
del df_dev
del df_copy

"""# Yêu cầu 3: Trình bày kết quả mô hình vào một bảng bằng thư viện Pandas"""

df_result = pd.DataFrame(data = {
                                 'RMSE_Train': [rmse_train_1, rmse_train_2, rmse_train_3,rmse_train_4,rmse_train_5,rmse_train_6,rmse_train_all],
                                 'RMSE_Dev': [rmse_dev_1, rmse_dev_2, rmse_dev_3,rmse_dev_4,rmse_dev_5,rmse_dev_6,rmse_dev_all],
                                 'RMSE_Test': [rmse_test_1, rmse_test_2, rmse_test_3,rmse_test_4,rmse_test_5,rmse_dev_6,rmse_test_all]
                                },
                         index = [
                                  'longitude', #1
                                  'longitude + latitude', #2
                                  'longitude + latitude + room_per_house', #3
                                  'longitude + latitude + housing_median_age', #4
                                  'longitude + latitude + median_income', #5
                                  'longitude + latitude + ocean_proximity', #6
                                  'all attributes', #all, include room_per_house
                                  ])
df_result

"""# Yêu cầu 4: Nhận xét các kết quả trên
Qua một vài thử nghiệm đối với việc kết hợp một số thuộc tính với nhau ta thấy rằng: 
*   Ta thấy rõ rằng khi chưa đưa các thuộc tính về cùng khoảng (scale) khiến cho RMSE đưa ra kết quả rất lớn (ví dụ như ``median_house_value `` và ``longtitude, latitude`` ) đây chính là điều ta không muốn
*   Việc tạo ra một số thuộc tính mới có sự liên quan cao hơn thuộc tính đã có tiêu biểu là ``room_per_house`` cũng có ảnh hưởng rất quan trọng đến kết quả của RMSE
*   Ta cũng cần lưu ý lựa chọn kĩ các thuộc tính quan trọng để tính toán và cũng để giảm thiểu khối công việc dư thừa không cần thiết, như ở bảng kết quả RMSE thì ta thấy có các thuộc tính quan trọng như ``longtitude``, ``latitude``, ``median_income`` và ``room_per_house``

# Yêu cầu 5: Thực hiện lại các Yêu cầu 2, 3, 4 khi dùng mô hình ``Support Vector Machine regressor`` (``sklearn.svm.SVR``) để giải quyết bài toán hồi quy tuyến tính
"""

from sklearn.svm import SVR
print('Import Linear Support Vector Regression successfully')

svm_reg = SVR(kernel="linear", ) #default parameter setting

"""Tương tự với các yêu cầu phía trên, ta cũng thử tính toán lại sử dụng các features list ở phía trên"""

# svr model 1 
modelSVM_1 = svm_reg.fit(train_X[features_list_1],train_Y)
rmseSVM_train_1 = mean_squared_error(train_Y,modelSVM_1.predict(train_X[features_list_1]) , squared=False) # If True returns MSE value, if False returns RMSE value.
rmseSVM_test_1 = mean_squared_error(test_Y,modelSVM_1.predict(test_X[features_list_1]) , squared=False)
rmseSVM_dev_1 = mean_squared_error(dev_Y,modelSVM_1.predict(dev_X[features_list_1]) , squared=False)

# svr model 2
modelSVM_2 = svm_reg.fit(train_X[features_list_2],train_Y)
rmseSVM_train_2 = mean_squared_error(train_Y,modelSVM_2.predict(train_X[features_list_2]) , squared=False) # If True returns MSE value, if False returns RMSE value.
rmseSVM_test_2 = mean_squared_error(test_Y,modelSVM_2.predict(test_X[features_list_2]) , squared=False)
rmseSVM_dev_2 = mean_squared_error(dev_Y,modelSVM_2.predict(dev_X[features_list_2]) , squared=False)

# svr model 3
modelSVM_3 = svm_reg.fit(train_X[features_list_3],train_Y)
rmseSVM_train_3 = mean_squared_error(train_Y,modelSVM_3.predict(train_X[features_list_3]) , squared=False) # If True returns MSE value, if False returns RMSE value.
rmseSVM_test_3 = mean_squared_error(test_Y,modelSVM_3.predict(test_X[features_list_3]) , squared=False)
rmseSVM_dev_3 = mean_squared_error(dev_Y,modelSVM_3.predict(dev_X[features_list_3]) , squared=False)

# svr model 4
modelSVM_4 = svm_reg.fit(train_X[features_list_4],train_Y)
rmseSVM_train_4 = mean_squared_error(train_Y,modelSVM_4.predict(train_X[features_list_4]) , squared=False) # If True returns MSE value, if False returns RMSE value.
rmseSVM_test_4 = mean_squared_error(test_Y,modelSVM_4.predict(test_X[features_list_4]) , squared=False)
rmseSVM_dev_4 = mean_squared_error(dev_Y,modelSVM_4.predict(dev_X[features_list_4]) , squared=False)

# svr model 5
modelSVM_5 = svm_reg.fit(train_X[features_list_5],train_Y)
rmseSVM_train_5 = mean_squared_error(train_Y,modelSVM_5.predict(train_X[features_list_5]) , squared=False) # If True returns MSE value, if False returns RMSE value.
rmseSVM_test_5 = mean_squared_error(test_Y,modelSVM_5.predict(test_X[features_list_5]) , squared=False)
rmseSVM_dev_5 = mean_squared_error(dev_Y,modelSVM_5.predict(dev_X[features_list_5]) , squared=False)

# svr model 6
modelSVM_6 = svm_reg.fit(train_X[features_list_6],train_Y)
rmseSVM_train_6 = mean_squared_error(train_Y,modelSVM_6.predict(train_X[features_list_6]) , squared=False) # If True returns MSE value, if False returns RMSE value.
rmseSVM_test_6 = mean_squared_error(test_Y,modelSVM_6.predict(test_X[features_list_6]) , squared=False)
rmseSVM_dev_6 = mean_squared_error(dev_Y,modelSVM_6.predict(dev_X[features_list_6]) , squared=False)

# svr model all
modelSVM_all = svm_reg.fit(train_X,train_Y)
rmseSVM_train_all = mean_squared_error(train_Y,modelSVM_all.predict(train_X) , squared=False) # If True returns MSE value, if False returns RMSE value.
rmseSVM_test_all = mean_squared_error(test_Y,modelSVM_all.predict(test_X) , squared=False)
rmseSVM_dev_all = mean_squared_error(dev_Y,modelSVM_all.predict(dev_X) , squared=False)

"""Thể hiện kết quả của mô hình khi sử dụng ``Support Vector Regression``"""

df_resultSVM = pd.DataFrame(data = {
                                 'rmseSVM_Train': [rmseSVM_train_1, rmseSVM_train_2, rmseSVM_train_3,rmseSVM_train_4,rmseSVM_train_5,rmseSVM_train_6,rmseSVM_train_all],
                                 'rmseSVM_Dev': [rmseSVM_dev_1, rmseSVM_dev_2, rmseSVM_dev_3,rmseSVM_dev_4,rmseSVM_dev_5,rmseSVM_dev_6,rmseSVM_dev_all],
                                 'rmseSVM_Test': [rmseSVM_test_1, rmseSVM_test_2, rmseSVM_test_3,rmseSVM_test_4,rmseSVM_test_5,rmseSVM_dev_6,rmseSVM_test_all]
                                },
                         index = [
                                  'longitude', #1
                                  'longitude + latitude', #2
                                  'longitude + latitude + room_per_house', #3
                                  'longitude + latitude + housing_median_age', #4
                                  'longitude + latitude + median_income', #5
                                  'longitude + latitude + ocean_proximity', #6
                                  'all attributes', #all, include room_per_house
                                  ])
df_resultSVM

"""### Nhận xét 
*   Ta thấy rằng việc để thông số mặc định khi sử dụng SVR (epsilon = 0.1, l2 penalty (C) = 1.0) làm cho kết quả trả về sai lệch cao hơn so với khi sử dụng OLS 
*    Vẫn tương tự như nhận xét ở OLS, cần feature scaling để kết quả trả về như ý muốn 
*    Cần lựa chọn các thuộc tính quan trọng thực hiện áp dụng cho mô hình để giảm chi phí tính toán và thời gian tính toán 
*    Thời gian tính toán của SVR lâu hơn rất nhiều so với OLS (sử dụng Google Colab để tính toán)
"""